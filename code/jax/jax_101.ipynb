{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7b5a82648ca4e2cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:04:21.344433Z",
     "start_time": "2025-07-09T10:04:18.047937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import time"
   ],
   "id": "b42bc442a2afe4be",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sample code",
   "id": "35914248efbf6220"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:03:48.213989Z",
     "start_time": "2025-07-08T18:03:48.204522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = jnp.array([1.0, 2.0, 3.0])\n",
    "b = jnp.arange(3.0, 6.0) # From 3.0 to up to (but not including) 6.0"
   ],
   "id": "d05ef529a259d7f7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:03:59.112762Z",
     "start_time": "2025-07-08T18:03:59.094493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(a)\n",
    "print(b)"
   ],
   "id": "256c12b6d2add252",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "[3. 4. 5.]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:05:13.828529Z",
     "start_time": "2025-07-08T18:05:13.819332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Element-wise addition\n",
    "c = a + b\n",
    "print(\"a + b:\", c)\n",
    "\n",
    "# Dot product\n",
    "d = jnp.dot(a, b)\n",
    "print(\"Dot product of a and b:\", d)\n",
    "\n",
    "# Reshaping\n",
    "e = jnp.zeros((2, 3))\n",
    "print(\"Zeros array, reshaped:\", e)\n",
    "\n",
    "# Transposing\n",
    "f = e.T\n",
    "print(\"Transposed array 'f':\\n\", f)"
   ],
   "id": "bea554d8e192b19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b: [4. 6. 8.]\n",
      "Dot product of a and b: 26.0\n",
      "Zeros array, reshaped: [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Transposed array 'f':\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# JAX immutability",
   "id": "a98344b41f1e7aba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:07:43.448293Z",
     "start_time": "2025-07-08T18:07:43.441870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np_arr = np.array([1.0, 2.0, 3.0])\n",
    "print(\"Original array 'np_arr':\\n\", np_arr)\n",
    "\n",
    "np_arr[0] = 99 # Modifying an element in-place\n",
    "print(\"Modified array 'np_arr':\\n\", np_arr)"
   ],
   "id": "7a91fed4f434d743",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array 'np_arr':\n",
      " [1. 2. 3.]\n",
      "Modified array 'np_arr':\n",
      " [99.  2.  3.]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:10:05.617407Z",
     "start_time": "2025-07-08T18:10:05.599239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "jax_arr = jnp.array([1.0, 2.0, 3.0])\n",
    "print(\"JAX array 'jax_arr':\\n\", jax_arr)\n",
    "\n",
    "try:\n",
    "    jax_arr[0] = 99\n",
    "except TypeError as e:\n",
    "    print(f\"Attempting in-place modification raised an error: {e}\")"
   ],
   "id": "77e07d5051f53c53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX array 'jax_arr':\n",
      " [1. 2. 3.]\n",
      "Attempting in-place modification raised an error: JAX arrays are immutable and do not support in-place item assignment. Instead of x[idx] = y, use x = x.at[idx].set(y) or another .at[] method: https://docs.jax.dev/en/latest/_autosummary/jax.numpy.ndarray.at.html\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# jax.grad",
   "id": "8fed92bfbcfd3f76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:23:02.949629Z",
     "start_time": "2025-07-08T18:23:02.927133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Get the gradient function for 'square'\n",
    "gradient_square = jax.grad(square)\n",
    "\n",
    "# Calculate the gradient at x = 3.0\n",
    "# The derivative of x^2 is 2x. So at x = 3, it should be 6.\n",
    "print(f\"Original function 'square(3.0)': {square(3.0)}\")\n",
    "print(f\"Gradient of square(x) at x=3.0: {gradient_square(3.0)}\")"
   ],
   "id": "ea0127b984c2daf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original function 'square(3.0)': 9.0\n",
      "Gradient of square(x) at x=3.0: 6.0\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Slightly more complicated function",
   "id": "dfb099cac2df34b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:24:52.484314Z",
     "start_time": "2025-07-08T18:24:52.472074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sin_square(x):\n",
    "    return jnp.sin(x ** 2)\n",
    "\n",
    "# Get its gradient function\n",
    "gradient_sin_square = jax.grad(sin_square)\n",
    "\n",
    "# Calculate the gradient at x = 1.0\n",
    "print(f\"\\nOriginal function 'sin_square(1.0)': {sin_square(1.0)}\")\n",
    "print(f\"Gradient of sin_square(x) at x=1.0: {gradient_sin_square(1.0)}\")\n",
    "print(f\"Expected: {2 * jnp.cos(1.0)}\") # Compare with manual calculation"
   ],
   "id": "543fd371da932807",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original function 'sin_square(1.0)': 0.8414709568023682\n",
      "Gradient of sin_square(x) at x=1.0: 1.0806045532226562\n",
      "Expected: 1.0806045532226562\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Function with multiple arguments",
   "id": "a0cb9640a5be4cc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:28:39.988467Z",
     "start_time": "2025-07-08T18:28:39.972933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sum_of_squares(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "# By default, jax.grad computes the gradient with respect to the first argument.\n",
    "grad_x_sum_of_squares = jax.grad(sum_of_squares)\n",
    "print(f\"\\nGradient of sum_of_squares w.r.t. x at (x=2, y=3): {grad_x_sum_of_squares(2.0, 3.0)}\") # Should be 2*2 = 4\n",
    "\n",
    "# To specify which arguments to differentiate with respect to, use 'argnums'.\n",
    "grad_xy_sum_of_squares = jax.grad(sum_of_squares, argnums=(0, 1))\n",
    "grad_x, grad_y = grad_xy_sum_of_squares(2.0, 3.0)\n",
    "print(f\"Gradient of sum_of_squares w.r.t. x and y at (x=2, y=3): x_grad={grad_x}, y_grad={grad_y}\") # Should be 4, 6"
   ],
   "id": "d6ed6cd00cc36f75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient of sum_of_squares w.r.t. x at (x=2, y=3): 4.0\n",
      "Gradient of sum_of_squares w.r.t. x and y at (x=2, y=3): x_grad=4.0, y_grad=6.0\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# jax.jit",
   "id": "1dda687fc1f6000c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:37:15.548873Z",
     "start_time": "2025-07-08T18:37:15.167681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A computationally intensive function\n",
    "def sum_large_array(x):\n",
    "    return jnp.sum(x * jnp.sin(x) / jnp.cosh(x) + jnp.log(x + 1))\n",
    "\n",
    "# Create a large JAX array\n",
    "large_array = jnp.arange(1, 1_00_001, dtype=jnp.float32) # From 1 to 1 million\n",
    "\n",
    "# Test without JIT\n",
    "start_time = time.time()\n",
    "result_non_jit = sum_large_array(large_array)\n",
    "end_time = time.time()\n",
    "print(f\"Non-JIT execution time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Test with JIT\n",
    "# Apply jax.jit as a decorator or directly wrap the function\n",
    "@jax.jit\n",
    "def sum_large_array_jitted(x):\n",
    "    return jnp.sum(x * jnp.sin(x) / jnp.cosh(x) + jnp.log(x + 1))\n",
    "\n",
    "# First call (compilation happens here)\n",
    "start_time = time.time()\n",
    "result_jit_first_call = sum_large_array_jitted(large_array)\n",
    "end_time = time.time()\n",
    "print(f\"JIT first call (with compilation) time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Subsequent calls (using compiled code)\n",
    "start_time = time.time()\n",
    "result_jit_subsequent_call = sum_large_array_jitted(large_array)\n",
    "end_time = time.time()\n",
    "print(f\"JIT subsequent call time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Verify results are the same\n",
    "print(f\"Results match: {jnp.allclose(result_non_jit, result_jit_first_call)}\")"
   ],
   "id": "28b7b87464125c03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-JIT execution time: 0.2244 seconds\n",
      "JIT first call (with compilation) time: 0.0381 seconds\n",
      "JIT subsequent call time: 0.0003 seconds\n",
      "Results match: True\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pure functions",
   "id": "79eddd7c3935f6f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example of an impure function",
   "id": "de204c7221185e25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:48:03.296082Z",
     "start_time": "2025-07-08T18:48:03.289014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "global_counter = 0\n",
    "\n",
    "def impure_add_and_increment(x):\n",
    "    global global_counter\n",
    "    global_counter += 1 # Side effect: modifies a global variable\n",
    "    # This print statement shows the internal state *during* the function call\n",
    "    print(f\"  (Inside function) global_counter after increment: {global_counter}\")\n",
    "    return x + global_counter\n",
    "\n",
    "print(\"--- Impure Function Example ---\")\n",
    "print(f\"Initial global_counter: {global_counter}\")\n",
    "\n",
    "# First call to the impure function\n",
    "result_1 = impure_add_and_increment(5)\n",
    "print(f\"First call impure_add_and_increment(5) returned: {result_1}\")\n",
    "print(f\"global_counter after first call: {global_counter}\") # Showing the side effect\n",
    "\n",
    "# Second call to the impure function\n",
    "result_2 = impure_add_and_increment(5)\n",
    "print(f\"Second call impure_add_and_increment(5) returned: {result_2}\")\n",
    "print(f\"global_counter after second call: {global_counter}\\n\") # Showing the side effect again\n",
    "\n",
    "print(f\"Final value of global_counter: {global_counter}\") # Final check of the modified global state\n"
   ],
   "id": "6314a6db9f8e1134",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Impure Function Example ---\n",
      "Initial global_counter: 0\n",
      "  (Inside function) global_counter after increment: 1\n",
      "First call impure_add_and_increment(5) returned: 6\n",
      "global_counter after first call: 1\n",
      "  (Inside function) global_counter after increment: 2\n",
      "Second call impure_add_and_increment(5) returned: 7\n",
      "global_counter after second call: 2\n",
      "\n",
      "Final value of global_counter: 2\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example of a pure function",
   "id": "12926f3fd8b8a9f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:53:26.515524Z",
     "start_time": "2025-07-08T18:53:26.508599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pure_add(x, y):\n",
    "    return x + y # Deterministic, no side effects\n",
    "\n",
    "def pure_transform_list(my_list):\n",
    "    # This creates a NEW list, it doesn't modify my_list in-place\n",
    "    return [item * 2 for item in my_list]\n",
    "\n",
    "print(\"\\n--- Pure Function Example ---\")\n",
    "print(f\"pure_add(5, 3) returned: {pure_add(5, 3)}\") # Always 8\n",
    "print(f\"pure_add(5, 3) returned: {pure_add(5, 3)}\") # Still 8\n",
    "print(\"Notice how pure_add always gives the same result for the same inputs and causes no external changes.\")\n",
    "\n",
    "original_list = [1, 2, 3]\n",
    "new_list = pure_transform_list(original_list) # Assuming pure_transform_list is defined from previous snippet\n",
    "print(\"\\nOriginal list (unchanged after pure transformation):\", original_list)\n",
    "print(\"New list (transformed by pure function):\", new_list)"
   ],
   "id": "73a29c4e6622bbb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pure Function Example ---\n",
      "pure_add(5, 3) returned: 8\n",
      "pure_add(5, 3) returned: 8\n",
      "Notice how pure_add always gives the same result for the same inputs and causes no external changes.\n",
      "\n",
      "Original list (unchanged after pure transformation): [1, 2, 3]\n",
      "New list (transformed by pure function): [2, 4, 6]\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# jax.pmap",
   "id": "e6ad8a18ece6e8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:04:25.073511Z",
     "start_time": "2025-07-09T10:04:24.968710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A function that operates on a single vector\n",
    "def elementwise_multiply_add(x, y):\n",
    "    # Imagine this is a complex operation on single data points\n",
    "    return x * 2 + y / 3\n",
    "\n",
    "# Define individual inputs\n",
    "x_single = jnp.array([1.0, 2.0, 3.0])\n",
    "y_single = jnp.array([4.0, 5.0, 6.0])\n",
    "\n",
    "print(f\"Result for single inputs: {elementwise_multiply_add(x_single, y_single)}\")"
   ],
   "id": "2e1f6cc6d5bd523c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for single inputs: [3.3333335 5.6666665 8.       ]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:04:28.715657Z",
     "start_time": "2025-07-09T10:04:28.700285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x_batch: batch of 2 vectors, each of size 3\n",
    "x_batch = jnp.array([[1.0, 2.0, 3.0],\n",
    "                     [4.0, 5.0, 6.0]])\n",
    "\n",
    "# y_batch: batch of 2 vectors, each of size 3\n",
    "y_batch = jnp.array([[10.0, 11.0, 12.0],\n",
    "                     [13.0, 14.0, 15.0]])"
   ],
   "id": "3815776ca607020d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:05:21.558445Z",
     "start_time": "2025-07-09T10:05:21.505702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = []\n",
    "for i in range(x_batch.shape[0]):\n",
    "    results.append(elementwise_multiply_add(x_batch[i], y_batch[i]))\n",
    "manual_batch_result = jnp.array(results)\n",
    "print(f\"Manual batch result: {manual_batch_result}\")"
   ],
   "id": "5f2ae39f65c4d079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual batch result: [[ 5.333333  7.666667 10.      ]\n",
      " [12.333334 14.666666 17.      ]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:06:09.640215Z",
     "start_time": "2025-07-09T10:06:09.571621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batched_elementwise_multiply_add = jax.vmap(elementwise_multiply_add)\n",
    "vmap_result = batched_elementwise_multiply_add(x_batch, y_batch)\n",
    "print(f\"vmap-batched result: {vmap_result}\")"
   ],
   "id": "ab4d95860b62162f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmap-batched result: [[ 5.333333  7.666667 10.      ]\n",
      " [12.333334 14.666666 17.      ]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:18:32.349620Z",
     "start_time": "2025-07-09T10:18:32.337683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jax.jit\n",
    "@jax.vmap\n",
    "def batched_loss_gradient(predictions, targets):\n",
    "    # This function operates on a single prediction-target pair\n",
    "    loss_fn = lambda p, t: jnp.mean((p - t)**2) # MSE Loss\n",
    "    # Gradient of loss w.r.t predictions\n",
    "    return jax.grad(loss_fn)(predictions, targets)"
   ],
   "id": "ccfbecb1bdba60cd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:18:34.807208Z",
     "start_time": "2025-07-09T10:18:34.765362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Batch data\n",
    "preds_batch = jnp.array([[1.0, 2.0], [3.0, 4.0]])\n",
    "targets_batch = jnp.array([[1.1, 2.1], [3.3, 4.5]])\n",
    "\n",
    "batched_grads = batched_loss_gradient(preds_batch, targets_batch)\n",
    "print(f\"\\nBatched gradients using vmap and grad: \\n{batched_grads}\")"
   ],
   "id": "e70f90e69509508f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batched gradients using vmap and grad: \n",
      "[[-0.10000002 -0.0999999 ]\n",
      " [-0.29999995 -0.5       ]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# vmap",
   "id": "86c1cb4922822f1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:25:38.196816Z",
     "start_time": "2025-07-09T10:25:38.185537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check available devices\n",
    "print(f\"\\nAvailable devices: {jax.devices()}\")\n",
    "num_devices = len(jax.devices())\n",
    "\n",
    "if num_devices < 2:\n",
    "    print(\"\\nSkipping pmap example: Requires at least 2 devices (e.g., multiple GPUs or CPU devices for simulation).\")\n",
    "else:\n",
    "    # A simple function that computes mean\n",
    "    def device_mean(x):\n",
    "        return jnp.mean(x)\n",
    "\n",
    "    # Let's create an array that we want to parallelize\n",
    "    data = jnp.arange(16.0).reshape(num_devices, -1)\n",
    "    print(f\"\\nData for pmap (sharded across devices):\\n{data}\")\n",
    "\n",
    "    # Use pmap to run device_mean on each slice of data on each device\n",
    "    pmapped_mean = jax.pmap(device_mean, axis_name='devices')\n",
    "\n",
    "    # Each device gets a slice of 'data' (e.g., data[0] on device 0, data[1] on device 1)\n",
    "    results_per_device = pmapped_mean(data)\n",
    "    print(f\"Mean calculated on each device:\\n{results_per_device}\")\n",
    "\n",
    "    # Often, you'll want to combine results from all devices.\n",
    "    def sum_across_devices(x):\n",
    "        # x here is the local part on each device\n",
    "        return jax.lax.psum(x, axis_name='devices')\n",
    "\n",
    "    # pmap this new function, using the same axis_name\n",
    "    pmapped_sum_across = jax.pmap(sum_across_devices, axis_name='devices')\n",
    "\n",
    "    # Each device computes its local sum, then sums these across devices\n",
    "    total_sum = pmapped_sum_across(data)\n",
    "\n",
    "    print(f\"Total sum across all devices (collective operation):\\n{total_sum[0]}\")\n",
    "    print(f\"Verified total sum: {jnp.sum(data)}\")"
   ],
   "id": "ddce36bb6ae1141e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available devices: [CpuDevice(id=0)]\n",
      "\n",
      "Skipping pmap example: Requires at least 2 devices (e.g., multiple GPUs or CPU devices for simulation).\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1b302ddc08ae520a"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
