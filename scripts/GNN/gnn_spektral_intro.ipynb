{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Libraries",
   "id": "f21e9cecd23fe52e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-08T01:28:22.820533Z",
     "start_time": "2025-07-08T01:28:22.814620Z"
    }
   },
   "source": "import numpy as np\nimport warnings\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Dropout, Input\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.random import set_seed\n\nfrom spektral.data.loaders import SingleLoader\nfrom spektral.datasets.citation import Citation\nfrom spektral.layers import GATConv\nfrom spektral.transforms import LayerPreprocess\n\n# Suppress SciPy sparse efficiency warnings\nwarnings.filterwarnings('ignore', category=RuntimeWarning, module='scipy.sparse')",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Seed",
   "id": "221ff64d68d3bf43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:28:24.725902Z",
     "start_time": "2025-07-08T01:28:24.719662Z"
    }
   },
   "cell_type": "code",
   "source": "set_seed(0)",
   "id": "b764818887a3b449",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "1757632ffc2a4302"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:28:25.988484Z",
     "start_time": "2025-07-08T01:28:25.884240Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = Citation(\"cora\", normalize_x=True, transforms=[LayerPreprocess(GATConv)])",
   "id": "81fba363f6222eab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igorlimarochaazevedo/Programming/deep_learning/.venv/lib/python3.10/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:31:53.659711Z",
     "start_time": "2025-07-08T01:31:53.650937Z"
    }
   },
   "cell_type": "code",
   "source": "print(type(dataset))",
   "id": "6e102942c6cdbe9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spektral.datasets.citation.Citation'>\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare Sample Weights",
   "id": "d369101ebb70d790"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:31:29.216510Z",
     "start_time": "2025-07-08T01:31:29.209067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mask_to_weights(mask):\n",
    "    return mask.astype(np.float32) / np.count_nonzero(mask)"
   ],
   "id": "56d159ada3862ee3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:44:10.203434Z",
     "start_time": "2025-07-08T01:44:10.193615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# training, validation, testing\n",
    "weights_tr, weights_va, weights_te = (\n",
    "    mask_to_weights(mask)\n",
    "    for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te)\n",
    ")"
   ],
   "id": "c25ef0e1241ece9a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:31:39.475048Z",
     "start_time": "2025-07-08T01:31:39.469300Z"
    }
   },
   "cell_type": "code",
   "source": "print(weights_tr.shape, weights_va.shape, weights_te.shape)",
   "id": "523d39fa10820e8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708,) (2708,) (2708,)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:34:19.107691Z",
     "start_time": "2025-07-08T01:34:19.097152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(weights_tr[:10])\n",
    "print(weights_va[:10])\n",
    "print(weights_te[:10])\n"
   ],
   "id": "8e183bef64fe9b0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00714286 0.00714286 0.00714286 0.00714286 0.00714286 0.00714286\n",
      " 0.00714286 0.00714286 0.00714286 0.00714286]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Parameters",
   "id": "3e9daf4b03582913"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:35:21.182605Z",
     "start_time": "2025-07-08T01:35:21.172804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "channels = 8  # Number of channels in each head of the first GAT layer\n",
    "n_attn_heads = 8  # Number of attention heads in first GAT layer\n",
    "dropout = 0.6  # Dropout rate for the features and adjacency matrix\n",
    "l2_reg = 2.5e-4  # L2 regularization rate\n",
    "learning_rate = 5e-3  # Learning rate\n",
    "epochs = 20000  # Number of training epochs\n",
    "patience = 100  # Patience for early stopping"
   ],
   "id": "eb056d7f504b095d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Graph Dimension",
   "id": "aec89614ce811268"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:37:22.534361Z",
     "start_time": "2025-07-08T01:37:22.523966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N = dataset.n_nodes  # Number of nodes in the graph\n",
    "F = dataset.n_node_features  # Original size of node features\n",
    "n_out = dataset.n_labels  # Number of classes"
   ],
   "id": "c3a5c043c4878ddc",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:43:01.502007Z",
     "start_time": "2025-07-08T01:43:01.494216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Nodes: {N}\")\n",
    "print(f\"Features: {F}\")\n",
    "print(f\"Num of classes: {n_out}\")"
   ],
   "id": "1131b1e1bc7cfe18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 2708\n",
      "Features: 1433\n",
      "Num of classes: 7\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Definition",
   "id": "2fa9c560b66929e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:43:16.758995Z",
     "start_time": "2025-07-08T01:43:16.663838Z"
    }
   },
   "cell_type": "code",
   "source": "# Model definition\n# -- Input\nx_in = Input(shape=(F,))\na_in = Input((N,), sparse=True) # (N,) for a square matrix of size N x N\n\n# -- Dropoout + Attention (Part 1)\ndo_1 = Dropout(dropout)(x_in)\n\n# Disable masking for GATConv to avoid None mask issues\nclass GATConvNoMask(GATConv):\n    def call(self, inputs, **kwargs):\n        # Remove mask from kwargs to prevent None mask issues\n        kwargs.pop('mask', None)\n        return super().call(inputs, **kwargs)\n\ngc_1 = GATConvNoMask(\n    channels,\n    attn_heads=n_attn_heads,\n    concat_heads=True,\n    dropout_rate=dropout,\n    activation=\"elu\",\n    kernel_regularizer=l2(l2_reg),\n    attn_kernel_regularizer=l2(l2_reg),\n    bias_regularizer=l2(l2_reg),\n)([do_1, a_in])\n\n# -- Dropoout + Attention (Part 2)\ndo_2 = Dropout(dropout)(gc_1)\ngc_2 = GATConvNoMask(\n    n_out,\n    attn_heads=1,\n    concat_heads=False,\n    dropout_rate=dropout,\n    activation=\"softmax\",\n    kernel_regularizer=l2(l2_reg),\n    attn_kernel_regularizer=l2(l2_reg),\n    bias_regularizer=l2(l2_reg),\n)([do_2, a_in])\n\n# Build model\nmodel = Model(inputs=[x_in, a_in], outputs=gc_2)",
   "id": "8cff3798af01d139",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Compilation",
   "id": "63d885113b1b44f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T01:44:42.891238Z",
     "start_time": "2025-07-08T01:44:42.841918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=CategoricalCrossentropy(reduction=\"sum\"),\n",
    "    weighted_metrics=[\"acc\"],\n",
    ")\n",
    "model.summary()"
   ],
   "id": "e3e6d37c20084fa6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1433\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1433\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ input_layer_2[\u001B[38;5;34m0\u001B[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2708\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_conv_no_mask    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │     \u001B[38;5;34m91,904\u001B[0m │ dropout_2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│ (\u001B[38;5;33mGATConvNoMask\u001B[0m)     │                   │            │ input_layer_3[\u001B[38;5;34m0\u001B[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ gat_conv_no_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_conv_no_mask_1  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m)         │        \u001B[38;5;34m469\u001B[0m │ dropout_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│ (\u001B[38;5;33mGATConvNoMask\u001B[0m)     │                   │            │ input_layer_3[\u001B[38;5;34m0\u001B[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1433</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1433</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2708</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_conv_no_mask    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">91,904</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GATConvNoMask</span>)     │                   │            │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gat_conv_no_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_conv_no_mask_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">469</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GATConvNoMask</span>)     │                   │            │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m92,373\u001B[0m (360.83 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,373</span> (360.83 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m92,373\u001B[0m (360.83 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,373</span> (360.83 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  Train Model",
   "id": "2da7642bbe3ac771"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-08T01:45:02.727615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train model\n",
    "loader_tr = SingleLoader(dataset, sample_weights=weights_tr)\n",
    "loader_va = SingleLoader(dataset, sample_weights=weights_va)\n",
    "model.fit(\n",
    "    loader_tr.load(),\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_data=loader_va.load(),\n",
    "    validation_steps=loader_va.steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
    ")"
   ],
   "id": "ad62a9283a1469fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1s/step - acc: 0.1857 - loss: 1.9496 - val_acc: 0.2620 - val_loss: 1.9470\n",
      "Epoch 2/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - acc: 0.2071 - loss: 1.9469 - val_acc: 0.4000 - val_loss: 1.9454\n",
      "Epoch 3/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - acc: 0.3857 - loss: 1.9440 - val_acc: 0.4280 - val_loss: 1.9449\n",
      "Epoch 4/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - acc: 0.4643 - loss: 1.9410 - val_acc: 0.4660 - val_loss: 1.9435\n",
      "Epoch 5/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - acc: 0.4143 - loss: 1.9400 - val_acc: 0.6120 - val_loss: 1.9409\n",
      "Epoch 6/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - acc: 0.4714 - loss: 1.9364 - val_acc: 0.6260 - val_loss: 1.9395\n",
      "Epoch 7/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - acc: 0.4929 - loss: 1.9351 - val_acc: 0.7080 - val_loss: 1.9379\n",
      "Epoch 8/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - acc: 0.4714 - loss: 1.9329 - val_acc: 0.7540 - val_loss: 1.9364\n",
      "Epoch 9/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - acc: 0.5143 - loss: 1.9307 - val_acc: 0.7980 - val_loss: 1.9344\n",
      "Epoch 10/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - acc: 0.6429 - loss: 1.9251 - val_acc: 0.7860 - val_loss: 1.9328\n",
      "Epoch 11/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - acc: 0.6214 - loss: 1.9197 - val_acc: 0.7800 - val_loss: 1.9317\n",
      "Epoch 12/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 145ms/step - acc: 0.5857 - loss: 1.9176 - val_acc: 0.7660 - val_loss: 1.9303\n",
      "Epoch 13/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - acc: 0.5500 - loss: 1.9197 - val_acc: 0.7380 - val_loss: 1.9294\n",
      "Epoch 14/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - acc: 0.6214 - loss: 1.9121 - val_acc: 0.7420 - val_loss: 1.9274\n",
      "Epoch 15/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - acc: 0.6429 - loss: 1.9064 - val_acc: 0.7620 - val_loss: 1.9244\n",
      "Epoch 16/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step - acc: 0.7000 - loss: 1.8967 - val_acc: 0.7780 - val_loss: 1.9208\n",
      "Epoch 17/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - acc: 0.6214 - loss: 1.8977 - val_acc: 0.7860 - val_loss: 1.9172\n",
      "Epoch 18/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - acc: 0.7143 - loss: 1.8980 - val_acc: 0.7960 - val_loss: 1.9133\n",
      "Epoch 19/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - acc: 0.6786 - loss: 1.8761 - val_acc: 0.7900 - val_loss: 1.9097\n",
      "Epoch 20/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - acc: 0.6714 - loss: 1.8938 - val_acc: 0.7940 - val_loss: 1.9060\n",
      "Epoch 21/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - acc: 0.7071 - loss: 1.8664 - val_acc: 0.7960 - val_loss: 1.9025\n",
      "Epoch 22/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - acc: 0.7429 - loss: 1.8565 - val_acc: 0.7880 - val_loss: 1.8989\n",
      "Epoch 23/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - acc: 0.6929 - loss: 1.8685 - val_acc: 0.7880 - val_loss: 1.8949\n",
      "Epoch 24/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - acc: 0.7500 - loss: 1.8606 - val_acc: 0.7680 - val_loss: 1.8905\n",
      "Epoch 25/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - acc: 0.6857 - loss: 1.8449 - val_acc: 0.7640 - val_loss: 1.8861\n",
      "Epoch 26/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - acc: 0.6857 - loss: 1.8410 - val_acc: 0.7620 - val_loss: 1.8818\n",
      "Epoch 27/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 57ms/step - acc: 0.7071 - loss: 1.8519 - val_acc: 0.7700 - val_loss: 1.8764\n",
      "Epoch 28/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - acc: 0.7286 - loss: 1.8185 - val_acc: 0.7740 - val_loss: 1.8711\n",
      "Epoch 29/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - acc: 0.7286 - loss: 1.8148 - val_acc: 0.7820 - val_loss: 1.8653\n",
      "Epoch 30/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - acc: 0.7071 - loss: 1.8016 - val_acc: 0.7820 - val_loss: 1.8609\n",
      "Epoch 31/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - acc: 0.7000 - loss: 1.7928 - val_acc: 0.7900 - val_loss: 1.8563\n",
      "Epoch 32/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - acc: 0.6786 - loss: 1.7896 - val_acc: 0.7900 - val_loss: 1.8507\n",
      "Epoch 33/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - acc: 0.7071 - loss: 1.7649 - val_acc: 0.7900 - val_loss: 1.8438\n",
      "Epoch 34/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - acc: 0.7786 - loss: 1.7647 - val_acc: 0.7980 - val_loss: 1.8369\n",
      "Epoch 35/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - acc: 0.7857 - loss: 1.7205 - val_acc: 0.8000 - val_loss: 1.8302\n",
      "Epoch 36/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - acc: 0.7286 - loss: 1.7536 - val_acc: 0.8020 - val_loss: 1.8232\n",
      "Epoch 37/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - acc: 0.7500 - loss: 1.7374 - val_acc: 0.8000 - val_loss: 1.8159\n",
      "Epoch 38/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - acc: 0.7429 - loss: 1.7158 - val_acc: 0.7960 - val_loss: 1.8084\n",
      "Epoch 39/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - acc: 0.7357 - loss: 1.7103 - val_acc: 0.7960 - val_loss: 1.8014\n",
      "Epoch 40/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - acc: 0.7357 - loss: 1.6959 - val_acc: 0.7940 - val_loss: 1.7946\n",
      "Epoch 41/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - acc: 0.7643 - loss: 1.6642 - val_acc: 0.7940 - val_loss: 1.7876\n",
      "Epoch 42/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - acc: 0.7357 - loss: 1.6689 - val_acc: 0.7880 - val_loss: 1.7799\n",
      "Epoch 43/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - acc: 0.7357 - loss: 1.6190 - val_acc: 0.7860 - val_loss: 1.7724\n",
      "Epoch 44/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - acc: 0.8071 - loss: 1.6340 - val_acc: 0.7940 - val_loss: 1.7646\n",
      "Epoch 45/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - acc: 0.7143 - loss: 1.6514 - val_acc: 0.7940 - val_loss: 1.7571\n",
      "Epoch 46/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - acc: 0.7429 - loss: 1.6162 - val_acc: 0.7960 - val_loss: 1.7498\n",
      "Epoch 47/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - acc: 0.7286 - loss: 1.6186 - val_acc: 0.8000 - val_loss: 1.7414\n",
      "Epoch 48/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - acc: 0.7643 - loss: 1.5875 - val_acc: 0.7980 - val_loss: 1.7329\n",
      "Epoch 49/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - acc: 0.8143 - loss: 1.5616 - val_acc: 0.8020 - val_loss: 1.7232\n",
      "Epoch 50/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - acc: 0.7643 - loss: 1.5660 - val_acc: 0.8000 - val_loss: 1.7129\n",
      "Epoch 51/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - acc: 0.7786 - loss: 1.5668 - val_acc: 0.8000 - val_loss: 1.7024\n",
      "Epoch 52/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - acc: 0.7929 - loss: 1.5418 - val_acc: 0.7960 - val_loss: 1.6929\n",
      "Epoch 53/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - acc: 0.7286 - loss: 1.5651 - val_acc: 0.8000 - val_loss: 1.6833\n",
      "Epoch 54/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - acc: 0.6857 - loss: 1.5801 - val_acc: 0.8040 - val_loss: 1.6734\n",
      "Epoch 55/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - acc: 0.7643 - loss: 1.5341 - val_acc: 0.8100 - val_loss: 1.6631\n",
      "Epoch 56/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 112ms/step - acc: 0.7714 - loss: 1.5321 - val_acc: 0.8060 - val_loss: 1.6538\n",
      "Epoch 57/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 95ms/step - acc: 0.7786 - loss: 1.5045 - val_acc: 0.8080 - val_loss: 1.6450\n",
      "Epoch 58/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step - acc: 0.8000 - loss: 1.4830 - val_acc: 0.8020 - val_loss: 1.6368\n",
      "Epoch 59/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - acc: 0.7714 - loss: 1.4526 - val_acc: 0.8020 - val_loss: 1.6276\n",
      "Epoch 60/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - acc: 0.7643 - loss: 1.4612 - val_acc: 0.8000 - val_loss: 1.6172\n",
      "Epoch 61/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - acc: 0.8357 - loss: 1.4592 - val_acc: 0.7980 - val_loss: 1.6063\n",
      "Epoch 62/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - acc: 0.7714 - loss: 1.4680 - val_acc: 0.8000 - val_loss: 1.5965\n",
      "Epoch 63/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - acc: 0.7714 - loss: 1.4208 - val_acc: 0.8020 - val_loss: 1.5871\n",
      "Epoch 64/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - acc: 0.7214 - loss: 1.4516 - val_acc: 0.8020 - val_loss: 1.5791\n",
      "Epoch 65/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - acc: 0.7857 - loss: 1.4567 - val_acc: 0.8020 - val_loss: 1.5702\n",
      "Epoch 66/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - acc: 0.7643 - loss: 1.4429 - val_acc: 0.8020 - val_loss: 1.5598\n",
      "Epoch 67/20000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - acc: 0.7643 - loss: 1.3504 - val_acc: 0.8040 - val_loss: 1.5506\n",
      "Epoch 68/20000\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
